TODO:

- Clean Elaboration data code
- MMD(X,Y) X is original data while Y are the generated samples; so idea is that we have mean embeddings (standard,
Nyström, Piv Cholesky, KernelHerding) we compute their inverse cdf such that we can simulate Y 
and finally we can compute MMD. remember kernel herding we dont need to invert cdf.
For MMD we compare xtrain with generated sample and see the performance of our methods.
- Explain how data have been retrieved, explain it in data and exploratory analysis chapter
- Explain upon which conditions KME and KDE are the same and when they differ
- in this paper "Nyström Kernel Mean Embeddings" they use Nyström approximation to reduce computations,
  thus try pivoted cholesky to see how it behaves. People have considered pivoted cholesky for kernels in general
  but have not considered Pivoted Cholesky Kernel Mean Embeddings.


DONE:
- Make polyfit for every desired order
- python code in src all lowercase for convention
- Consider spline instead of polynomial so that we mitigate oscillations ==> results are reasonable

- Risolvere sistema rational polynomial con QR instead of least squares normal equations formula