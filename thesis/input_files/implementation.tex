This section is inteneded to explain and aid for reproducibilty studies. Hereafter the specific libraries used and the custom implementatios are thoroughly documented.
\\
For the list of python packages needed see the requirement.txt file.


Section documenting code
- indicate computer specifics

- Explain how methods' implementation has been
adapted to my specific setting.

- Explain in detail how to my src code has been implemented
its rationale and how to use it.

- As I explain code scripts go over the test, to 
explain better my ideas.

- Indicate also hyperparameters maybe in each subsection

\section{Point forecasting}
\subsection{Multiple linear regression}
For multiple linear regression the one from the \href{https://scikit-learn.org/stable/}{sklearn} library has been used.

\subsection{Tbats}
Tbats implementation is available at \url{https://github.com/intive-DataScience/tbatsx}.
In our application we specified as hyperparameters the lenght of seasons; 24 for the daily seasonality and 168 for the weekly seasonality.

\subsection{Prophet}
The prophet models has been applied by employing the python API provided by Meta \href{https://facebook.github.io/prophet/docs/quick_start.html}{prophet}.

\subsection{K-nearest neighbours}
The object KNeighborsRegressor of the sklearn module neighbors has been used.

\subsection{Support vector regression}
The object SVR of the sklearn module svm has been used by specifying the liner kernel.

\subsection{LSTM}
The LSTM predictor has been built using the \href{https://pytorch.org}{torch} library.

\subsection{Kernel ridge regression}
The object KernelRidge of the sklearn module kernel\_ridge has been used.

\subsection{Kernel support vector regression}
The object SVR of the sklearn module svm has been used by specifying rbf as the kernel parameter.

\section{Probabilistic forecasting}
\subsection{Linear quantile regression}
The implementation of statsmodels.regression.quantile\_regression.QuantReg has been used.
The model is fitted through iterative reweighted least squares.
\subsection{Quantile gradient boosting machine}
The implementation of sklearn.ensemble.GradientBoostingRegressor has been used.
\subsection{Quantile forest}
The implementation of quantile\_forest.RandomForestQuantileRegressor has been used. This estimator is compatible with scikit-learn.
\subsection{Kernel quantile regression}
Kernel quantile regression had no previously implemented open source library, thus the need of implementing our own version.
\\
The scikit-learn team provides a project template for the creation of estimators compatible with scikit-learn functionalities. Therefore, the KQR class is derived from the scikit-learn BaseEstimator and the mixin class RegressorMixin.
Our KQR class is initialized by providing a quantile, the regularization term C and the rbf kernel bandwidth gamma; the latter are the two hyperparameters of our custom estimator.
\\
In the fit method, we set up and solve the convex optimisation problem by using the cvxopt library. 
When using this library, it is important to keep two things in mind. First this library assumes the quadratic term of the optimisation problem to be multiplied by the 0.5 factor, thus we just have to provide the Q matrix with no 0.5 in front.
Secondly, in order to specify multiple inequalities we have to stack them an provide as a unique matrix.
\\
Once a solution to the convex problem has been found, we create a mask for the support vectors of the estimator in order to estimate the constant term of our kernel quantile regressor.
\\
In the predict method, we pass a matrix X\_eval of independent variables, next we compute the kernel matrix between X\_train and X\_eval and obtain y\_eval with the formula $y=\alpha^\intercal K+b$.
\\
This estimator is compatible with useful scikit-learn in built methods like gridsearch, crossvalidation and scoring rules.
\\
Up to now, there are only two open source implementation of the quantile kernel regression. Nevertheless they are both in R, that is there exists no python, matlab or julia open source implementation. Following are reported the results of a comparative study between our own implementation and the one of the R library kernlab
% (i guess it is in C or C++ and then binded to R).
\subsubsection{Python vs R implementation}
In this section, a comparison study has been carried out in order to inspect the competitiveness of our implementation with the existing one for the R programming language.